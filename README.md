ğŸ•¸ï¸ Web Scraper Collection â€“ Quotes & Books

This project includes two Python-based web scrapers:
- ğŸ“œ **Quote Scraper**: Extracts inspirational quotes from [quotes.toscrape.com](https://quotes.toscrape.com)
- ğŸ“š **Book Scraper**: Collects book data (title, price, rating) from [books.toscrape.com](https://books.toscrape.com)

Each scraper saves data into a .csv file and includes a basic Flask API for local access. Docker support is included.

ğŸ”§ Technologies Used
- Python 3
- BeautifulSoup4
- Requests
- Flask (for APIs)
- Docker (optional)
- CSV module

ğŸ“œ Quote Scraper

ğŸ“ How It Works
1. Sends a GET request to https://quotes.toscrape.com.
2. Parses the HTML using BeautifulSoup.
3. Extracts quotes from <span class="text">.
4. Saves them into quotes.csv.

ğŸ–¥ï¸ How To Run

python scraper.py

ğŸ“š Book Scraper
ğŸ“ How It Works
Sends GET requests through all paginated book pages at https://books.toscrape.com.

Extracts: Title, Price, Availability, Rating

Saves them into books.csv.

ğŸ–¥ï¸ How To Run

python book-scraper.py

ğŸ§ª API Endpoints (Flask)
Each scraper also has its own API:

ğŸ“œ Quote API

python scraper_api.py
GET /quotes: Returns all quotes in JSON

ğŸ“š Book API

python book_api.py
GET /books: Returns all books in JSON

ğŸ³ Docker Support
You can build and run each scraper's API using Docker.

Example: Book Scraper

docker build -t book-api .
docker run -p 8080:8080 book-api
Then visit: http://localhost:8080/books

ğŸ“¦ Sample Output
CSV files will be generated as:

quotes.csv
books.csv
  